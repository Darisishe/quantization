[2025-05-06 07:34:39,065]: 
Training LeNet5 with relu_scnd
[2025-05-06 07:35:13,733]: [LeNet5_relu_scnd] Epoch: 001 Train Loss: 2.2985 Train Acc: 0.1304 Eval Loss: 2.2847 Eval Acc: 0.1413 (LR: 0.001000)
[2025-05-06 07:35:47,977]: [LeNet5_relu_scnd] Epoch: 002 Train Loss: 2.2119 Train Acc: 0.1824 Eval Loss: 2.0915 Eval Acc: 0.2282 (LR: 0.001000)
[2025-05-06 07:36:21,586]: [LeNet5_relu_scnd] Epoch: 003 Train Loss: 2.0343 Train Acc: 0.2476 Eval Loss: 1.9507 Eval Acc: 0.2873 (LR: 0.001000)
[2025-05-06 07:36:54,827]: [LeNet5_relu_scnd] Epoch: 004 Train Loss: 1.9184 Train Acc: 0.2939 Eval Loss: 1.7945 Eval Acc: 0.3464 (LR: 0.001000)
[2025-05-06 07:37:27,824]: [LeNet5_relu_scnd] Epoch: 005 Train Loss: 1.8064 Train Acc: 0.3349 Eval Loss: 1.6828 Eval Acc: 0.3838 (LR: 0.001000)
[2025-05-06 07:38:01,181]: [LeNet5_relu_scnd] Epoch: 006 Train Loss: 1.7208 Train Acc: 0.3665 Eval Loss: 1.6187 Eval Acc: 0.4098 (LR: 0.001000)
[2025-05-06 07:38:34,779]: [LeNet5_relu_scnd] Epoch: 007 Train Loss: 1.6728 Train Acc: 0.3831 Eval Loss: 1.5690 Eval Acc: 0.4208 (LR: 0.001000)
[2025-05-06 07:39:08,227]: [LeNet5_relu_scnd] Epoch: 008 Train Loss: 1.6395 Train Acc: 0.3963 Eval Loss: 1.5232 Eval Acc: 0.4499 (LR: 0.001000)
[2025-05-06 07:39:40,962]: [LeNet5_relu_scnd] Epoch: 009 Train Loss: 1.6077 Train Acc: 0.4124 Eval Loss: 1.5188 Eval Acc: 0.4451 (LR: 0.001000)
[2025-05-06 07:40:13,759]: [LeNet5_relu_scnd] Epoch: 010 Train Loss: 1.5816 Train Acc: 0.4196 Eval Loss: 1.4799 Eval Acc: 0.4572 (LR: 0.001000)
[2025-05-06 07:40:47,103]: [LeNet5_relu_scnd] Epoch: 011 Train Loss: 1.5575 Train Acc: 0.4320 Eval Loss: 1.4373 Eval Acc: 0.4770 (LR: 0.001000)
[2025-05-06 07:41:21,627]: [LeNet5_relu_scnd] Epoch: 012 Train Loss: 1.5401 Train Acc: 0.4367 Eval Loss: 1.4265 Eval Acc: 0.4886 (LR: 0.001000)
[2025-05-06 07:41:54,561]: [LeNet5_relu_scnd] Epoch: 013 Train Loss: 1.5140 Train Acc: 0.4478 Eval Loss: 1.4018 Eval Acc: 0.4925 (LR: 0.001000)
[2025-05-06 07:42:27,294]: [LeNet5_relu_scnd] Epoch: 014 Train Loss: 1.5015 Train Acc: 0.4531 Eval Loss: 1.3837 Eval Acc: 0.5004 (LR: 0.001000)
[2025-05-06 07:43:00,070]: [LeNet5_relu_scnd] Epoch: 015 Train Loss: 1.4779 Train Acc: 0.4608 Eval Loss: 1.3567 Eval Acc: 0.5105 (LR: 0.001000)
[2025-05-06 07:43:33,220]: [LeNet5_relu_scnd] Epoch: 016 Train Loss: 1.4607 Train Acc: 0.4704 Eval Loss: 1.3401 Eval Acc: 0.5171 (LR: 0.001000)
[2025-05-06 07:44:06,805]: [LeNet5_relu_scnd] Epoch: 017 Train Loss: 1.4395 Train Acc: 0.4766 Eval Loss: 1.3232 Eval Acc: 0.5250 (LR: 0.001000)
[2025-05-06 07:44:40,189]: [LeNet5_relu_scnd] Epoch: 018 Train Loss: 1.4278 Train Acc: 0.4839 Eval Loss: 1.3044 Eval Acc: 0.5313 (LR: 0.001000)
[2025-05-06 07:45:13,221]: [LeNet5_relu_scnd] Epoch: 019 Train Loss: 1.4115 Train Acc: 0.4892 Eval Loss: 1.2935 Eval Acc: 0.5353 (LR: 0.001000)
[2025-05-06 07:45:46,336]: [LeNet5_relu_scnd] Epoch: 020 Train Loss: 1.3980 Train Acc: 0.4944 Eval Loss: 1.2681 Eval Acc: 0.5478 (LR: 0.001000)
[2025-05-06 07:45:46,339]: [LeNet5_relu_scnd] Best Eval Accuracy: 0.5478
[2025-05-06 07:45:46,343]: 
Training of full-precision model finished!
[2025-05-06 07:45:46,343]: Model Architecture:
[2025-05-06 07:45:46,343]: LeNet5(
  (conv1): Sequential(
    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (conv2): Sequential(
    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(in_features=400, out_features=120, bias=True)
    (1): ReLU(inplace=True)
  )
  (fc2): Sequential(
    (0): Linear(in_features=120, out_features=84, bias=True)
    (1): ReLU(inplace=True)
  )
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
[2025-05-06 07:45:46,343]: 
Model Weights:
[2025-05-06 07:45:46,343]: 
Layer: conv1.0
Layer Shape: torch.Size([6, 3, 5, 5])
[2025-05-06 07:45:46,356]: Sample Values (16 elements): [0.03525857999920845, -0.0015916259726509452, -0.08025696873664856, -0.029757564887404442, 0.10176818072795868, -0.1487141102552414, -0.204696387052536, 0.12497935444116592, -0.15804104506969452, 0.24169790744781494, -0.04179220274090767, 0.23138542473316193, 0.10962475836277008, 0.14665059745311737, 0.08153866231441498, 0.08054748922586441]
[2025-05-06 07:45:46,363]: Mean: -0.0010
[2025-05-06 07:45:46,370]: Min: -0.3329
[2025-05-06 07:45:46,371]: Max: 0.2922
[2025-05-06 07:45:46,371]: 
Layer: conv2.0
Layer Shape: torch.Size([16, 6, 5, 5])
[2025-05-06 07:45:46,372]: Sample Values (16 elements): [0.04048068821430206, -0.05535406991839409, 0.04076390340924263, -0.06512296199798584, 0.1433219611644745, 0.043633271008729935, 0.09657873213291168, 0.005271035712212324, -0.0028059326577931643, 0.13508132100105286, -0.06035345047712326, -0.027376407757401466, -0.021860431879758835, -0.08146031945943832, -0.11199802905321121, 0.010741238482296467]
[2025-05-06 07:45:46,372]: Mean: 0.0080
[2025-05-06 07:45:46,372]: Min: -0.1974
[2025-05-06 07:45:46,372]: Max: 0.2454
[2025-05-06 07:45:46,373]: 
Layer: fc1.0
Layer Shape: torch.Size([120, 400])
[2025-05-06 07:45:46,374]: Sample Values (16 elements): [0.018199307844042778, -0.0193382129073143, 0.018530698493123055, -0.05112757161259651, -0.029006971046328545, -0.04856077581644058, -0.02288638800382614, -0.01362001895904541, -0.04556312412023544, 0.003185991896316409, 0.03787313774228096, 0.0466521792113781, 0.056536950170993805, 0.02723594754934311, 0.013874927535653114, 0.007813069969415665]
[2025-05-06 07:45:46,374]: Mean: 0.0006
[2025-05-06 07:45:46,374]: Min: -0.1223
[2025-05-06 07:45:46,374]: Max: 0.1132
[2025-05-06 07:45:46,374]: 
Layer: fc2.0
Layer Shape: torch.Size([84, 120])
[2025-05-06 07:45:46,375]: Sample Values (16 elements): [-0.08300294727087021, -0.04002739489078522, 0.05098680779337883, 0.026119716465473175, 0.06008990854024887, -0.019393859431147575, -0.05476115271449089, -0.015778150409460068, 0.0790049284696579, 0.03219474479556084, 0.02473035268485546, 0.011100917123258114, 0.04848673939704895, 0.024984918534755707, -0.11886683851480484, -0.05384693294763565]
[2025-05-06 07:45:46,375]: Mean: 0.0020
[2025-05-06 07:45:46,375]: Min: -0.1536
[2025-05-06 07:45:46,376]: Max: 0.1831
[2025-05-06 07:45:46,376]: 
Layer: fc3
Layer Shape: torch.Size([10, 84])
[2025-05-06 07:45:46,376]: Sample Values (16 elements): [-0.03364146500825882, -0.1238921657204628, 0.024883585050702095, -0.19622133672237396, 0.09248548746109009, -0.16519679129123688, 0.07114145159721375, 0.10341502726078033, 0.04353274032473564, 0.19895190000534058, 0.21426580846309662, -0.06288222223520279, -0.06874873489141464, -0.14100180566310883, -0.13806940615177155, -0.03437844663858414]
[2025-05-06 07:45:46,376]: Mean: 0.0011
[2025-05-06 07:45:46,376]: Min: -0.3141
[2025-05-06 07:45:46,377]: Max: 0.3115
[2025-05-06 07:45:46,377]: 


QAT of LeNet5 with relu_scnd down to 4 bits...
[2025-05-06 07:45:46,424]: [LeNet5_relu_scnd_quantized_4_bits] after configure_qat:
[2025-05-06 07:45:46,499]: LeNet5(
  (quant): QuantStub(
    (activation_post_process): FakeQuantize(
      fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=15, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)
      (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)
    )
  )
  (dequant): DeQuantStub()
  (conv1): Sequential(
    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (conv2): Sequential(
    (0): Conv2d(
      6, 16, kernel_size=(5, 5), stride=(1, 1)
      (weight_fake_quant): FakeQuantize(
        fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=15, dtype=torch.qint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)
        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)
      )
      (activation_post_process): NoopObserver()
    )
    (1): Sequential(
      (0): ReLU(inplace=True)
      (1): QuantStub(
        (activation_post_process): FakeQuantize(
          fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=15, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)
          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)
        )
      )
    )
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fc1): Sequential(
    (0): Linear(
      in_features=400, out_features=120, bias=True
      (weight_fake_quant): FakeQuantize(
        fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=15, dtype=torch.qint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)
        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)
      )
      (activation_post_process): NoopObserver()
    )
    (1): Sequential(
      (0): ReLU(inplace=True)
      (1): QuantStub(
        (activation_post_process): FakeQuantize(
          fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=15, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)
          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)
        )
      )
    )
  )
  (fc2): Sequential(
    (0): Linear(
      in_features=120, out_features=84, bias=True
      (weight_fake_quant): FakeQuantize(
        fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=15, dtype=torch.qint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)
        (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)
      )
      (activation_post_process): NoopObserver()
    )
    (1): Sequential(
      (0): ReLU(inplace=True)
      (1): QuantStub(
        (activation_post_process): FakeQuantize(
          fake_quant_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), observer_enabled=tensor([1], device='cuda:0', dtype=torch.uint8), quant_min=0, quant_max=15, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.], device='cuda:0'), zero_point=tensor([0], device='cuda:0', dtype=torch.int32)
          (activation_post_process): MovingAverageMinMaxObserver(min_val=inf, max_val=-inf)
        )
      )
    )
  )
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
[2025-05-06 07:46:21,910]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 001 Train Loss: 1.4221 Train Acc: 0.4817 Eval Loss: 1.3067 Eval Acc: 0.5324 (LR: 0.001000)
[2025-05-06 07:46:58,157]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 002 Train Loss: 1.4182 Train Acc: 0.4861 Eval Loss: 1.3086 Eval Acc: 0.5257 (LR: 0.001000)
[2025-05-06 07:47:33,077]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 003 Train Loss: 1.4036 Train Acc: 0.4942 Eval Loss: 1.2947 Eval Acc: 0.5301 (LR: 0.001000)
[2025-05-06 07:48:07,907]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 004 Train Loss: 1.3947 Train Acc: 0.4969 Eval Loss: 1.2885 Eval Acc: 0.5327 (LR: 0.001000)
[2025-05-06 07:48:42,788]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 005 Train Loss: 1.3882 Train Acc: 0.4980 Eval Loss: 1.2846 Eval Acc: 0.5353 (LR: 0.001000)
[2025-05-06 07:49:17,618]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 006 Train Loss: 1.3778 Train Acc: 0.5032 Eval Loss: 1.2628 Eval Acc: 0.5381 (LR: 0.001000)
[2025-05-06 07:49:52,237]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 007 Train Loss: 1.3642 Train Acc: 0.5057 Eval Loss: 1.2561 Eval Acc: 0.5418 (LR: 0.001000)
[2025-05-06 07:50:27,015]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 008 Train Loss: 1.3679 Train Acc: 0.5073 Eval Loss: 1.2668 Eval Acc: 0.5386 (LR: 0.001000)
[2025-05-06 07:51:01,653]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 009 Train Loss: 1.3608 Train Acc: 0.5069 Eval Loss: 1.2676 Eval Acc: 0.5440 (LR: 0.001000)
[2025-05-06 07:51:36,414]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 010 Train Loss: 1.3495 Train Acc: 0.5128 Eval Loss: 1.2337 Eval Acc: 0.5498 (LR: 0.001000)
[2025-05-06 07:52:11,050]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 011 Train Loss: 1.3469 Train Acc: 0.5148 Eval Loss: 1.2255 Eval Acc: 0.5568 (LR: 0.001000)
[2025-05-06 07:52:45,691]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 012 Train Loss: 1.3329 Train Acc: 0.5182 Eval Loss: 1.2539 Eval Acc: 0.5478 (LR: 0.001000)
[2025-05-06 07:53:20,315]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 013 Train Loss: 1.3284 Train Acc: 0.5199 Eval Loss: 1.2171 Eval Acc: 0.5620 (LR: 0.001000)
[2025-05-06 07:53:55,131]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 014 Train Loss: 1.3232 Train Acc: 0.5237 Eval Loss: 1.2153 Eval Acc: 0.5621 (LR: 0.001000)
[2025-05-06 07:54:29,910]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 015 Train Loss: 1.3170 Train Acc: 0.5244 Eval Loss: 1.2160 Eval Acc: 0.5606 (LR: 0.001000)
[2025-05-06 07:55:04,679]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 016 Train Loss: 1.3100 Train Acc: 0.5297 Eval Loss: 1.2047 Eval Acc: 0.5648 (LR: 0.001000)
[2025-05-06 07:55:39,472]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 017 Train Loss: 1.3033 Train Acc: 0.5322 Eval Loss: 1.1907 Eval Acc: 0.5687 (LR: 0.001000)
[2025-05-06 07:56:14,104]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 018 Train Loss: 1.2966 Train Acc: 0.5304 Eval Loss: 1.2028 Eval Acc: 0.5603 (LR: 0.001000)
[2025-05-06 07:56:49,015]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 019 Train Loss: 1.2973 Train Acc: 0.5322 Eval Loss: 1.2254 Eval Acc: 0.5545 (LR: 0.001000)
[2025-05-06 07:57:23,739]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 020 Train Loss: 1.2891 Train Acc: 0.5348 Eval Loss: 1.1844 Eval Acc: 0.5750 (LR: 0.001000)
[2025-05-06 07:57:58,365]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 021 Train Loss: 1.2859 Train Acc: 0.5395 Eval Loss: 1.2170 Eval Acc: 0.5611 (LR: 0.001000)
[2025-05-06 07:58:32,907]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 022 Train Loss: 1.2793 Train Acc: 0.5390 Eval Loss: 1.1798 Eval Acc: 0.5751 (LR: 0.001000)
[2025-05-06 07:59:07,590]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 023 Train Loss: 1.2783 Train Acc: 0.5395 Eval Loss: 1.1713 Eval Acc: 0.5783 (LR: 0.001000)
[2025-05-06 07:59:42,123]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 024 Train Loss: 1.2704 Train Acc: 0.5454 Eval Loss: 1.1956 Eval Acc: 0.5676 (LR: 0.001000)
[2025-05-06 08:00:16,826]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 025 Train Loss: 1.2675 Train Acc: 0.5441 Eval Loss: 1.1882 Eval Acc: 0.5733 (LR: 0.001000)
[2025-05-06 08:00:51,658]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 026 Train Loss: 1.2620 Train Acc: 0.5466 Eval Loss: 1.1711 Eval Acc: 0.5782 (LR: 0.001000)
[2025-05-06 08:01:26,283]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 027 Train Loss: 1.2625 Train Acc: 0.5466 Eval Loss: 1.1606 Eval Acc: 0.5813 (LR: 0.001000)
[2025-05-06 08:02:00,865]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 028 Train Loss: 1.2546 Train Acc: 0.5499 Eval Loss: 1.1532 Eval Acc: 0.5879 (LR: 0.001000)
[2025-05-06 08:02:35,392]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 029 Train Loss: 1.2500 Train Acc: 0.5511 Eval Loss: 1.1427 Eval Acc: 0.5850 (LR: 0.001000)
[2025-05-06 08:03:10,121]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 030 Train Loss: 1.2483 Train Acc: 0.5522 Eval Loss: 1.1591 Eval Acc: 0.5807 (LR: 0.000250)
[2025-05-06 08:03:44,884]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 031 Train Loss: 1.2199 Train Acc: 0.5637 Eval Loss: 1.1267 Eval Acc: 0.5926 (LR: 0.000250)
[2025-05-06 08:04:19,503]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 032 Train Loss: 1.2191 Train Acc: 0.5637 Eval Loss: 1.1327 Eval Acc: 0.5879 (LR: 0.000250)
[2025-05-06 08:04:54,080]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 033 Train Loss: 1.2156 Train Acc: 0.5628 Eval Loss: 1.1306 Eval Acc: 0.5904 (LR: 0.000250)
[2025-05-06 08:05:28,574]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 034 Train Loss: 1.2103 Train Acc: 0.5659 Eval Loss: 1.1360 Eval Acc: 0.5876 (LR: 0.000250)
[2025-05-06 08:06:03,247]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 035 Train Loss: 1.2138 Train Acc: 0.5675 Eval Loss: 1.1368 Eval Acc: 0.5914 (LR: 0.000250)
[2025-05-06 08:06:37,990]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 036 Train Loss: 1.2108 Train Acc: 0.5670 Eval Loss: 1.1299 Eval Acc: 0.5906 (LR: 0.000250)
[2025-05-06 08:07:12,776]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 037 Train Loss: 1.2127 Train Acc: 0.5646 Eval Loss: 1.1267 Eval Acc: 0.5948 (LR: 0.000250)
[2025-05-06 08:07:47,515]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 038 Train Loss: 1.2109 Train Acc: 0.5667 Eval Loss: 1.1221 Eval Acc: 0.5925 (LR: 0.000250)
[2025-05-06 08:08:22,173]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 039 Train Loss: 1.2115 Train Acc: 0.5640 Eval Loss: 1.1301 Eval Acc: 0.5912 (LR: 0.000250)
[2025-05-06 08:08:56,987]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 040 Train Loss: 1.2094 Train Acc: 0.5662 Eval Loss: 1.1250 Eval Acc: 0.5943 (LR: 0.000250)
[2025-05-06 08:09:31,785]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 041 Train Loss: 1.2105 Train Acc: 0.5641 Eval Loss: 1.1276 Eval Acc: 0.5937 (LR: 0.000250)
[2025-05-06 08:10:06,618]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 042 Train Loss: 1.2089 Train Acc: 0.5662 Eval Loss: 1.1256 Eval Acc: 0.5925 (LR: 0.000250)
[2025-05-06 08:10:43,282]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 043 Train Loss: 1.2085 Train Acc: 0.5676 Eval Loss: 1.1212 Eval Acc: 0.5942 (LR: 0.000250)
[2025-05-06 08:11:19,890]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 044 Train Loss: 1.2049 Train Acc: 0.5674 Eval Loss: 1.1189 Eval Acc: 0.5991 (LR: 0.000250)
[2025-05-06 08:11:56,348]: [LeNet5_relu_scnd_quantized_4_bits] Epoch: 045 Train Loss: 1.2039 Train Acc: 0.5681 Eval Loss: 1.1172 Eval Acc: 0.5984 (LR: 0.000063)
