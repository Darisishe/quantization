{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa36258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResNet18_relu_quantized_2_bits] Unique activations of initial at Epoch epoch - 260619: [0.0000000e+00 7.2400780e-07 1.3116235e-05 ... 5.8292041e+00 5.9081454e+00\n",
      " 5.9467082e+00]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer1.block1.act1 at Epoch 1 - 3: [0.        2.8491902 5.6983805]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer1.block1.act2 at Epoch 1 - 3: [0.       4.090436 8.180872]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer1.block2.act1 at Epoch 1 - 4: [0.        2.8498256 5.6996512 8.549477 ]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer1.block2.act2 at Epoch 1 - 3: [ 0.         5.3530293 10.7060585]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer2.block1.act1 at Epoch 1 - 3: [0.        2.7572467 5.5144935]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer2.block1.act2 at Epoch 1 - 3: [0.       4.072831 8.145662]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer2.block2.act1 at Epoch 1 - 4: [0.        2.7283628 5.4567256 8.185088 ]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer2.block2.act2 at Epoch 1 - 4: [ 0.         5.4283442 10.8566885 16.285032 ]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer3.block1.act1 at Epoch 1 - 4: [0.        2.7891302 5.5782604 8.367391 ]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer3.block1.act2 at Epoch 1 - 4: [ 0.         4.0499096  8.099819  12.149729 ]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer3.block2.act1 at Epoch 1 - 4: [0.        2.8036995 5.607399  8.4110985]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer3.block2.act2 at Epoch 1 - 4: [ 0.        5.474641 10.949282 16.423923]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer4.block1.act1 at Epoch 1 - 4: [0.       2.713987 5.427974 8.141961]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer4.block1.act2 at Epoch 1 - 4: [ 0.         3.9785755  7.957151  11.935726 ]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer4.block2.act1 at Epoch 1 - 4: [0.        2.594746  5.189492  7.7842383]\n",
      "[ResNet18_relu_quantized_2_bits] Unique activations of layer4.block2.act2 at Epoch 1 - 4: [ 0.         5.2648115 10.529623  15.794435 ]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of initial at Epoch epoch - 261608: [0.0000000e+00 2.7218719e-06 5.2536020e-06 ... 5.5235620e+00 5.5616422e+00\n",
      " 5.7901068e+00]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer1.block1.act1 at Epoch 1 - 5: [0.        1.2372054 2.4744108 3.711616  4.9488215]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer1.block1.act2 at Epoch 1 - 7: [ 0.         1.8247826  3.6495652  5.474348   7.2991304  9.123913\n",
      " 10.948696 ]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer1.block2.act1 at Epoch 1 - 6: [0.        1.110481  2.220962  3.331443  4.441924  5.5524054]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer1.block2.act2 at Epoch 1 - 6: [ 0.         2.1714635  4.342927   6.5143905  8.685854  10.857317 ]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer2.block1.act1 at Epoch 1 - 7: [0.        1.1194217 2.2388434 3.3582652 4.477687  5.597109  6.7165303]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer2.block1.act2 at Epoch 1 - 7: [0.        1.4602047 2.9204094 4.3806143 5.840819  7.3010235 8.761229 ]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer2.block2.act1 at Epoch 1 - 6: [0.        0.9455077 1.8910154 2.836523  3.7820308 4.7275386]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer2.block2.act2 at Epoch 1 - 6: [0.        1.8746955 3.749391  5.6240864 7.498782  9.373478 ]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer3.block1.act1 at Epoch 1 - 7: [0.        0.9655857 1.9311714 2.8967571 3.8623428 4.8279285 5.7935143]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer3.block1.act2 at Epoch 1 - 7: [0.        1.3912385 2.782477  4.1737156 5.564954  6.956192  8.347431 ]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer3.block2.act1 at Epoch 1 - 8: [0.         0.95524323 1.9104865  2.8657298  3.820973   4.776216\n",
      " 5.7314596  6.6867027 ]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer3.block2.act2 at Epoch 1 - 8: [ 0.         1.9058222  3.8116443  5.7174664  7.6232886  9.529111\n",
      " 11.434933  13.340755 ]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer4.block1.act1 at Epoch 1 - 8: [0.        0.9274551 1.8549103 2.7823653 3.7098205 4.6372757 5.5647306\n",
      " 6.492186 ]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer4.block1.act2 at Epoch 1 - 8: [ 0.         1.4611709  2.9223418  4.3835125  5.8446836  7.305855\n",
      "  8.767025  10.228196 ]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer4.block2.act1 at Epoch 1 - 8: [0.        0.9571761 1.9143522 2.8715281 3.8287044 4.7858806 5.7430563\n",
      " 6.7002325]\n",
      "[ResNet18_relu_quantized_3_bits] Unique activations of layer4.block2.act2 at Epoch 1 - 8: [ 0.         1.9376079  3.8752158  5.812824   7.7504315  9.68804\n",
      " 11.625648  13.563255 ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of initial at Epoch epoch - 262749: [0.0000000e+00 2.8903219e-06 3.9247134e-06 ... 5.4548554e+00 5.4959688e+00\n",
      " 5.5143695e+00]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer1.block1.act1 at Epoch 1 - 11: [0.        0.6140781 1.2281562 1.8422344 2.4563124 3.0703905 3.6844687\n",
      " 4.298547  4.912625  5.526703  6.140781 ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer1.block1.act2 at Epoch 1 - 11: [0.        0.9050041 1.8100082 2.7150123 3.6200163 4.5250206 5.4300246\n",
      " 6.3350286 7.2400327 8.145037  9.050041 ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer1.block2.act1 at Epoch 1 - 12: [0.        0.5534126 1.1068252 1.6602378 2.2136505 2.7670631 3.3204756\n",
      " 3.8738883 4.427301  4.9807134 5.5341263 6.0875387]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer1.block2.act2 at Epoch 1 - 12: [ 0.        1.144052  2.288104  3.432156  4.576208  5.72026   6.864312\n",
      "  8.008364  9.152416 10.296469 11.44052  12.584572]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer2.block1.act1 at Epoch 1 - 12: [0.         0.52941084 1.0588217  1.5882325  2.1176434  2.6470542\n",
      " 3.176465   3.7058759  4.2352867  4.7646976  5.2941084  5.823519  ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer2.block1.act2 at Epoch 1 - 14: [0.        0.7191154 1.4382308 2.1573462 2.8764615 3.5955768 4.3146925\n",
      " 5.0338078 5.752923  6.4720383 7.1911535 7.9102693 8.629385  9.3485   ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer2.block2.act1 at Epoch 1 - 12: [0.        0.4615003 0.9230006 1.3845009 1.8460011 2.3075013 2.7690017\n",
      " 3.2305021 3.6920023 4.1535025 4.6150026 5.0765033]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer2.block2.act2 at Epoch 1 - 11: [0.         0.87932485 1.7586497  2.6379745  3.5172994  4.396624\n",
      " 5.275949   6.155274   7.034599   7.9139237  8.793248  ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer3.block1.act1 at Epoch 1 - 12: [0.         0.44814885 0.8962977  1.3444465  1.7925954  2.240744\n",
      " 2.688893   3.137042   3.5851908  4.0333395  4.481488   4.9296374 ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer3.block1.act2 at Epoch 1 - 13: [0.         0.66619146 1.3323829  1.9985744  2.6647658  3.3309574\n",
      " 3.9971488  4.66334    5.3295317  5.9957232  6.661915   7.328106\n",
      " 7.9942975 ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer3.block2.act1 at Epoch 1 - 13: [0.         0.45296526 0.9059305  1.3588958  1.811861   2.2648263\n",
      " 2.7177916  3.1707568  3.623722   4.0766873  4.5296526  4.982618\n",
      " 5.435583  ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer3.block2.act2 at Epoch 1 - 15: [ 0.         0.8762103  1.7524205  2.6286309  3.504841   4.3810515\n",
      "  5.2572618  6.133472   7.009682   7.8858924  8.762103   9.638313\n",
      " 10.5145235 11.390734  13.143154 ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer4.block1.act1 at Epoch 1 - 16: [0.         0.45040408 0.90080816 1.3512123  1.8016163  2.2520204\n",
      " 2.7024245  3.1528285  3.6032326  4.0536366  4.5040407  4.954445\n",
      " 5.404849   5.855253   6.305657   6.756061  ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer4.block1.act2 at Epoch 1 - 16: [ 0.         0.6947123  1.3894246  2.084137   2.7788491  3.4735613\n",
      "  4.168274   4.862986   5.5576982  6.2524104  6.9471226  7.641835\n",
      "  8.336548   9.03126    9.725972  10.420684 ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer4.block2.act1 at Epoch 1 - 16: [0.         0.45411596 0.9082319  1.3623478  1.8164638  2.2705798\n",
      " 2.7246957  3.1788118  3.6329277  4.087044   4.5411596  4.9952755\n",
      " 5.4493914  5.903507   6.3576236  6.8117394 ]\n",
      "[ResNet18_relu_quantized_4_bits] Unique activations of layer4.block2.act2 at Epoch 1 - 16: [ 0.          0.93498546  1.8699709   2.8049564   3.7399418   4.674927\n",
      "  5.609913    6.544898    7.4798837   8.414869    9.349854   10.28484\n",
      " 11.219826   12.154811   13.089796   14.024782  ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_histograms_and_scalars(logs_dir='raw_np', plots_dir='plots', bins=50):\n",
    "    \"\"\"\n",
    "    Generate bar histograms for activations and line plots for training statistics.\n",
    "    \"\"\"\n",
    "    # Ensure plots directory exists\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate through each model directory in logs\n",
    "    for model_name in os.listdir(logs_dir):\n",
    "        model_log_dir = os.path.join(logs_dir, model_name)\n",
    "        if not os.path.isdir(model_log_dir):\n",
    "            continue\n",
    "            \n",
    "        # Create model-specific plot directories\n",
    "        model_plot_dir = os.path.join(plots_dir, model_name)\n",
    "        activations_plot_dir = os.path.join(model_plot_dir, 'activations')\n",
    "        scalars_plot_dir = os.path.join(model_plot_dir, 'training')\n",
    "        os.makedirs(activations_plot_dir, exist_ok=True)\n",
    "        os.makedirs(scalars_plot_dir, exist_ok=True)\n",
    "        \n",
    "        # Plot histograms for activations\n",
    "        acts_dir = os.path.join(model_log_dir, 'activations')\n",
    "        for file in os.listdir(acts_dir):\n",
    "            if file.endswith('.npy'):\n",
    "                file_path = os.path.join(acts_dir, file)\n",
    "                act = np.load(file_path)\n",
    "                layer_name = file.split('_')[0]\n",
    "                epoch = file.split('_')[2].split('.')[0]\n",
    "                \n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.hist(act.flatten(), bins=bins, density=True)\n",
    "                plt.title(f'Activation Histogram for {layer_name} at Epoch {epoch}\\n{model_name}')\n",
    "                plt.xlabel('Activation Value')\n",
    "                plt.ylabel('Density')\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.savefig(os.path.join(activations_plot_dir, f'{layer_name}_epoch_{epoch}.png'))\n",
    "                plt.close()\n",
    "                if \"quant\" in model_name:\n",
    "                    a = np.unique(act.flatten())\n",
    "                    print(f\"[{model_name}] Unique activations of {layer_name} at Epoch {epoch} - {len(a)}:\", a)\n",
    "        # Plot training statistics\n",
    "        scalars_file = os.path.join(model_log_dir, 'training_stats.npz')\n",
    "        if os.path.exists(scalars_file):\n",
    "            data = np.load(scalars_file)\n",
    "            epochs = data['epoch']\n",
    "            \n",
    "            # Plot losses\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(epochs, data['train_loss'], label='Train Loss')\n",
    "            plt.plot(epochs, data['eval_loss'], label='Eval Loss')\n",
    "            plt.title(f'Losses vs. Epoch\\n{model_name}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.savefig(os.path.join(scalars_plot_dir, 'losses.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Plot accuracies\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(epochs, data['train_acc'], label='Train Accuracy')\n",
    "            plt.plot(epochs, data['eval_acc'], label='Eval Accuracy')\n",
    "            plt.title(f'Accuracies vs. Epoch\\n{model_name}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.savefig(os.path.join(scalars_plot_dir, 'accuracies.png'))\n",
    "            plt.close()\n",
    "            \n",
    "            # Plot learning rate\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.plot(epochs, data['learning_rate'], label='Learning Rate')\n",
    "            plt.title(f'Learning Rate vs. Epoch\\n{model_name}')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Learning Rate')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            plt.savefig(os.path.join(scalars_plot_dir, 'learning_rate.png'))\n",
    "            plt.close()\n",
    "\n",
    "plot_histograms_and_scalars()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
